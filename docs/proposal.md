---
layout: default
title: Proposal
---
# Project Proposal

## Part 2.2 Summary of the Project
The primary goal of my project is to build a simplified Generative Pre-trained Transformer (GPT) from scratch. The project aims to explore and implement the fundamental mechanics of transformer models, focusing on understanding their architecture and functionality. The input to the model will be a sequence of tokens (e.g., text represented as tokenized words or subwords), and the output will be the predicted next token in the sequence, enabling text generation capabilities. This project has applications in natural language processing tasks such as text completion, dialogue generation, and creative writing tools.

## Part 2.3 AI/ML Algorithms
The project will implement a transformer-based neural network using self-attention mechanisms and feedforward layers to predict the next token in a sequence. The method falls under unsupervised learning and sequence modeling, utilizing autoregressive language modeling.

## Part 2.4 Evaluation Plan
### Quantitative Evaluation
The success of the project will be evaluated using standard language modeling metrics such as perplexity, which measures how well the model predicts a test dataset. A baseline will be established using a small unigram or bigram language model, and I aim to significantly lower perplexity compared to these simpler models. The model will be trained and evaluated on a subset of publicly available text data, such as classic literature or open-source datasets like WikiText or Gutenberg.

### Qualitative Analysis
To verify the model's performance qualitatively, I will analyze its ability to generate coherent and contextually relevant text. Toy examples, such as predicting words in simple sentences or generating short paragraphs, will be used for initial sanity checks. Visualization tools, such as attention heatmaps, will help understand how the model allocates attention across tokens. The moonshot case will involve generating text that demonstrates a strong grasp of context, grammar, and creativity, such as completing prompts or producing stylistically consistent passages.

## Part 2.6 AI Tool Usage
AI tools were used during the initial stages of this project to brainstorm ideas, structure the project proposal, and refine the project's scope. These tools helped generate potential use cases and suggested approaches for implementing the transformer architecture. All outputs from AI tools were critically reviewed and adjusted to ensure they aligned with the objectives of the project and contributed meaningfully to its development.







